{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cv2 설치하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### random: 랜덤 관련한 함수들을 모아놓은 모듈\n",
    "#### pandas: 데이터분석 라이브러리, 행과 열로 이루어진 데이터 객체를 만들어서 다룸.\n",
    "#### numpy: 과학 계산을 위한 라이브러리로서 다차원 배열을 처리하는데 필요한 여러 유용한 기능을 제공\n",
    "#### os: Operating System의 약자로서 운영체제에서 제공되는 여러 기능을 파이썬에서 수행\n",
    "#### cv2: 실시간 영상 처리에 중점을 둔 영상 처리 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn-preprocessing: 스케일링 및 변수변환을 위한 StandardScaler 클래스는 기능을 제공\n",
    "#### sklearn-countvectorizer: 문서를 token count matrix로 변환하는 클래스\n",
    "#### sklearn-train_test_split: 손쉽게 train set(학습 데이터 셋)과 test set(테스트 셋)을 분리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch 모듈 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch: 오픈소스 머신 러닝 라이브러리, 자동 미분 모듈, 최적화 모듈, 이미지 처리 모듈, 오디오 처리 모듈 등 머신 러닝 및 딥러닝을 위한 다양한 모듈 제공\n",
    "#### torch-nn: 신경망 모델 정의 (클래스)\n",
    "#### torch-optim: 다양한 최적화 알고리즈을 구현한 패키지, 모델 매개변수 최적화\n",
    "#### torch-F: 신경망 모델 정의 (함수)\n",
    "#### torch-Dataset, DataLoader: Dataset 은 샘플과 정답(label)을 저장하고, DataLoader 는 Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감쌉니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tqdm: 반복문이 어디까지 진행되었는지 표시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### albumentations 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A \n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "from albumentations.pytorch.transforms import ToTensorV2 \n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### albumentations: 이미지를 손쉽게 aygmentation 해주는 파이썬 라이브러리이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sklearn의 분류 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### warnings: 경고 메세지 무시하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gpu 사용하기 위한 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':128,\n",
    "    'EPOCHS':5,\n",
    "    'LEARNING_RATE':0.01,\n",
    "    'BATCH_SIZE':32,\n",
    "    'SEED':41\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 사이즈, 이폭, 학습률, 배치사이즈, 시드 고정\n",
    "#### epoch: 훈련 데이터셋에 포함된 모든 데이터들이 한 번씩 모댈을 통과한 횟수로, 모든 학습 데이터셋을 학습하는 횟수를 의미한다. \n",
    "#### epoch가 5회라면, 학습 데이터 셋을 5회 모델에 학습시켰다는 것이다.\n",
    "#### epoch를 높일수록, 다양한 무작위 가중치를 학습해보므로, 적합한 파라미터를 찾을 확률이 올라간다. 하지만 지나치게 높이게 되면, 과적합 현상이 일어날 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### batch size는 연산 한 번에 들어가는 데이터의 크기를 가리킨다.\n",
    "#### 배치 사이즈가 너무 큰 경우 한 번에 처리해야 할 데이터의 양이 많아지므로, 학습 속도가 느려지고, 메모리 부족 문제가 발생할 위험이 있다.\n",
    "#### 반대로 배치 사이즈가 너무 작은 경우 적은 데이터를 대상으로 가중치를 업데이트하고, 이 업데이트가 자주발생하므로, 훈련이 불안정해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Load & Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv('C:/Users/moond/open/Data/train.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, _, _ = train_test_split(all_df, all_df['cat3'], test_size=0.2, random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train set, validation set 구별"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_df['cat3'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 카테고리형 데이터를 수치형으로 변환하는 labelencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cat3'] = le.transform(train_df['cat3'].values)\n",
    "val_df['cat3'] = le.transform(val_df['cat3'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cat3에 labelencoder를 적용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### overview를 vectorize하는 vectorizer 선언, 최대 특성 수는 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = vectorizer.fit_transform(train_df['overview'])\n",
    "train_vectors = train_vectors.todense()\n",
    "\n",
    "val_vectors = vectorizer.transform(val_df['overview'])\n",
    "val_vectors = val_vectors.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13588, 4096)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3398, 4096)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### albumentations 라이브러리를 이용하여 이미지 데이터 다루기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### albumentation으로 데이터를 커스터마이징하면 훨씬 자유도가 높고 속도가 빠르지만, pytorch data pipeine까지 직접 커스텀해야함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. data pipeline 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, img_path_list, text_vectors, label_list, transforms, infer=False):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.text_vectors = text_vectors\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        self.infer = infer\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "    \n",
    "        img_path = self.img_path_list[index] # 이미지 읽기\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image=image)['image'] # transforms 적용\n",
    "            \n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __init__()은 반드시 첫 번째 인수로 self를 지정해야한다. self에는 인스턴스 자체가 전달되어 있다. 이로 인해, 최과 메소드 내에 인스턴스 변수를 작성하거나, 참고하는 것이 가능해진다. \n",
    "#### tranform()은 특질들을 추출하는 함수로 기존에 있던 특질로부터 새로운 특질을 추출할 떄 사용한다.\n",
    "#### 파이프라인을 사용하면 데이터 전처리와 모델 학습, 예측까지 한번에 가능하여 코드도 간결해지는 장점이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # Label\n",
    "        if self.infer: # infer == True, test_data로부터 label \"결과 추출\" 시 사용\n",
    "            return image, torch.Tensor(text_vector).view(-1)\n",
    "        else: # infer == False\n",
    "            label = self.label_list[index] # dataframe에서 label 가져와 \"학습\" 시 사용\n",
    "            return image, torch.Tensor(text_vector).view(-1), label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. data augmentation 적용하기 (image를 resize한 뒤에 normalize를 적용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moond\\open\\Code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 지정\n",
    "\n",
    "train_path = 'C:/Users/moond/open/Code/train2'\n",
    "test_path = 'C:/Users/moond/open/Code/test2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_trans = transforms.Compose([\n",
    "                                   transforms.Resize((128,128)),\n",
    "                                   transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_train = torchvision.datasets.ImageFolder(root=train_path, transform=resize_trans)\n",
    "resize_test = torchvision.datasets.ImageFolder(root=test_path, transform=resize_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3137, 0.3098, 0.3020,  ..., 0.1490, 0.1529, 0.1529],\n",
       "         [0.3137, 0.3098, 0.3059,  ..., 0.1529, 0.1529, 0.1529],\n",
       "         [0.3137, 0.3098, 0.3059,  ..., 0.1569, 0.1529, 0.1529],\n",
       "         ...,\n",
       "         [0.4980, 0.4863, 0.4824,  ..., 0.3490, 0.3569, 0.3490],\n",
       "         [0.4784, 0.4078, 0.3647,  ..., 0.3490, 0.3569, 0.3529],\n",
       "         [0.3294, 0.3137, 0.3098,  ..., 0.3608, 0.3569, 0.3569]],\n",
       "\n",
       "        [[0.3412, 0.3373, 0.3333,  ..., 0.2196, 0.2196, 0.2196],\n",
       "         [0.3412, 0.3373, 0.3373,  ..., 0.2275, 0.2235, 0.2235],\n",
       "         [0.3412, 0.3373, 0.3373,  ..., 0.2275, 0.2235, 0.2275],\n",
       "         ...,\n",
       "         [0.4314, 0.4196, 0.4118,  ..., 0.2980, 0.2980, 0.2902],\n",
       "         [0.4157, 0.3451, 0.3059,  ..., 0.2980, 0.3059, 0.2980],\n",
       "         [0.2784, 0.2706, 0.2667,  ..., 0.3020, 0.3020, 0.2980]],\n",
       "\n",
       "        [[0.4118, 0.4157, 0.4157,  ..., 0.3608, 0.3608, 0.3529],\n",
       "         [0.4157, 0.4118, 0.4157,  ..., 0.3608, 0.3569, 0.3529],\n",
       "         [0.4157, 0.4118, 0.4118,  ..., 0.3608, 0.3608, 0.3569],\n",
       "         ...,\n",
       "         [0.3647, 0.3569, 0.3490,  ..., 0.2431, 0.2431, 0.2392],\n",
       "         [0.3490, 0.2902, 0.2549,  ..., 0.2431, 0.2510, 0.2471],\n",
       "         [0.2353, 0.2235, 0.2196,  ..., 0.2510, 0.2510, 0.2471]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resize_train[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36114624, 0.3708664 , 0.379108  ], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(resize_train[0][0].numpy(),axis=(1,2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41174626, 0.37635332, 0.38942945], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(resize_test[0][0].numpy(),axis=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(dataset):\n",
    "  meanRGB = [np.mean(image.numpy(), axis=(1,2)) for image,_ in dataset]\n",
    "  stdRGB = [np.std(image.numpy(), axis=(1,2)) for image,_ in dataset]\n",
    "\n",
    "  meanR = np.mean([m[0] for m in meanRGB])\n",
    "  meanG = np.mean([m[1] for m in meanRGB])\n",
    "  meanB = np.mean([m[2] for m in meanRGB])\n",
    "\n",
    "  stdR = np.mean([s[0] for s in stdRGB])\n",
    "  stdG = np.mean([s[1] for s in stdRGB])\n",
    "  stdB = np.mean([s[2] for s in stdRGB])\n",
    "\n",
    "  print(meanR, meanG, meanB)\n",
    "  print(stdR, stdG, stdB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49876145 0.49929118 0.4725662\n",
      "0.23629072 0.23496795 0.26324624\n"
     ]
    }
   ],
   "source": [
    "get_mean_std(resize_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5003475 0.500986 0.4740023\n",
      "0.23637316 0.23554333 0.2639925\n"
     ]
    }
   ],
   "source": [
    "get_mean_std(resize_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "A.Normalize(mean=(0.499, 0.499, 0.473), std=(0.236, 0.235, 0.263), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "A.Resize(CFG['IMG_SIZE'],CFG['IMG_SIZE']),\n",
    "A.Normalize(mean=(0.5, 0.5, 0.474), std=(0.236, 0.236, 0.264), max_pixel_value=255.0, always_apply=False, p=1.0),\n",
    "ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지 데이터 normalization\n",
    "#### transform = A.Compose([])을 이용하여 이미지와 라벨 각각에 Augmentation을 적용하기 위한 객체를 생성\n",
    "#### 128x128 size로 resize\n",
    "#### Normalize() -> 입력 받은 이미지 값의 범위를 (0, 255) → (-1, 1) 범위로 줄여주는 역할\n",
    "#### ToTensorV2 -> tensor형 변환 (tensor: 딥러닝에서 데이터를 처리하기 위한 데이터의 형태)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. albumentation으로 data augmentation해주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __init__(self, img_path_list, text_vectors, label_list, transforms, infer=False)\n",
    "train_dataset = ImageDataset(train_df['img_path'].values, train_vectors, train_df['cat3'].values, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0) \n",
    "\n",
    "val_dataset = ImageDataset(val_df['img_path'].values, val_vectors, val_df['cat3'].values, test_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataloader() -> 모델에 데이터를 넣어주기 전, 적당한 양씩 데이터를 나누는 과정이 필요하게 되고 dataloader에서 이 과정을 수월하게 만들어주는 기능을 한다.\n",
    "#### Dataset() -> 데이터의 집합을 의미\n",
    "#### shuffle() -> 리스트를 무작위로 셔플하기, 순서 섞기\n",
    "#### num_workers -> 학습 도충 CPU의 작업을 몇 개의 코어를 사용해서 진행할지에 대한 설정 파라미터입니다. #### 하이퍼파라미터를 튜닝하는 것처럼 모델에 가장 적합한 num_workers 수치를 찾아내는 것도 파라미터 튜닝이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이미지의 픽셀 0~255, 이것의 중간값인 128x128 크기로 변환/ train test 이미지 둘 다 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageCNN(nn.Module):\n",
    "    def __init__(self, num_classes=len(le.classes_)):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.cnn_extract = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2), \n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_feature = self.cnn_extract(img) # cnn_extract 적용\n",
    "        img_feature = torch.flatten(img_feature, start_dim=1) # 1차원으로 변환\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### input_channel = 3: RGB 3개의 채널이기 때문\n",
    "#### out_channel = 8: 출력하는 채널 8개\n",
    "#### kernel_size = 3: convolution의 시야를 결정. 보통 2d에서 3x3 픽셀로 사용합니다.\n",
    "#### stride = 1: 이미지를 횡단할 떄 커널의 스텝 사이즈를 결정. 기본값은 1이지만 보통 max pooling과 비슷하게 이미지를 다운샘플링하기 위해 stride를 2로 사용할 수 있습니다.\n",
    "#### ReLu() = Rectified Linear Unit의 약자로 입력이 0이하면 0으로 침묵, 0을 넘으면 입력 그대로를 출력하는 함수"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
